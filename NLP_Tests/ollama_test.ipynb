{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.vectorstores import Weaviate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('../data/Reading 2 Text Analytics for Beginners using NLTK_240116_161801.pdf')\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gen = ''\n",
    "for page in data:\n",
    "    text_gen += page.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1024,\n",
    "    chunk_overlap = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_gen = text_splitter.split_text(text_gen)\n",
    "len(chunks_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Text Analytics for Beginners using NLTK \\nReference: https://www.datacamp.com/community/tutor ials/text-analytics-beginners-nltk \\nIn today's area of internet and online services, da ta is generating at incredible speed and amount. \\nGenerally, Data analyst, engineer, and scientists a re handling relational or tabular data. These \\ntabular data columns have either numerical or categ orical data. Generated data has a variety of \\nstructures such as text, image, audio, and video. O nline activities such as articles, website text, \\nblog posts, social media posts are generating unstr uctured textual data. Corporate and business \\nneed to analyze textual data to understand customer  activities, opinion, and feedback to \\nsuccessfully derive their business. To compete with  big textual data, text analytics is evolving at a \\nfaster rate than ever before. \\nIn this tutorial, you are going to cover the follow ing topics: \\n\\uf0b7 Text Analytics and NLP \\n\\uf0b7 Compare Text Analytics, NLP and Text Mining\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_gen = [Document(page_content=t) for t in chunks_gen]\n",
    "document_gen[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store doc in vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chescore/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/chescore/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/chescore/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceBgeEmbeddings(model_name='BAAI/bge-small-en-v1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chescore/anaconda3/lib/python3.11/site-packages/weaviate/warnings.py:121: DeprecationWarning: Dep005: You are using weaviate-client version 3.26.2. The latest version is 4.4.4.\n",
      "            Please consider upgrading to the latest version. See https://weaviate.io/developers/weaviate/client-libraries/python for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vector_store = Weaviate.from_documents(document_gen, \n",
    "                                    embedding_model, \n",
    "                                    weaviate_url = 'http://localhost:8080'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type='similarity',\n",
    "    search_kwargs={'k': 2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What is NLTK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o Text Analysis Operations using NLTK \n",
      "o Tokenization \n",
      "o Stopwords \n",
      "o Lexicon Normalization such as Stemming and Lemmatiz ation  \n",
      "o POS Tagging \n",
      "Text Analysis Operations using NLTK \n",
      "NLTK is a powerful Python package that provides a s et of diverse natural languages algorithms. \n",
      "It is free, opensource, easy to use, large communit y, and well documented. NLTK consists of the \n",
      "most common algorithms such as tokenizing, part-of- speech tagging, stemming, sentiment \n",
      "analysis, topic segmentation, and named entity reco gnition. NLTK helps the computer to \n",
      "analysis, preprocess, and understand the written te xt. \n",
      "Tokenization \n",
      "Tokenization is the first step in text analytics. T he process of breaking down a text paragraph into \n",
      "smaller chunks such as words or sentence is called Tokenization. Token is a single entity that is \n",
      "building blocks for sentence or paragraph. \n",
      "Sentence Tokenization \n",
      "Sentence tokenizer breaks text paragraph into sente nces. \n",
      "from nltk.tokenize import sent_tokenize\n"
     ]
    }
   ],
   "source": [
    "docs = vector_store.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model='mistral:7b-instruct-q4_K_M', temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "   ### [INST]\n",
    "   Instruction: You are an expert at answering NLP questions.\n",
    "   Here is context to help: {context}\n",
    "   ##QUESTION:\n",
    "   {question}\n",
    "   [/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template='\\n   ### [INST]\\n   Instruction: You are an expert at answering NLP questions.\\n   Here is context to help: {context}\\n   ##QUESTION:\\n   {question}\\n   [/INST]\\n')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=['context', 'question'],\n",
    "    template=prompt_template\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NLTK stands for Natural Language Toolkit. It is a popular Python library used for natural language processing (NLP) tasks such as tokenization, stemming, tagging, parsing, and classification. NLTK provides a wide range of tools and resources for working with text data, including pre-trained models, corpora, and utilities for data cleaning and preprocessing. It is widely used in academia and industry for tasks such as sentiment analysis, machine translation, and information extraction.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {'context': retriever, 'question': RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' NLTK stands for Natural Language Toolkit. It is a powerful Python package that provides a set of diverse natural language algorithms. NLTK is free, opensource, easy to use, has a large community, and is well documented. NLTK consists of the most common algorithms such as tokenizing, part-of-speech tagging, stemming, sentiment analysis, topic segmentation, and named entity recognition. NLTK helps computers analyze, preprocess, and understand written text.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
